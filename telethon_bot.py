import asyncio
import logging
import os
from typing import Optional, List

from dotenv import load_dotenv
from telethon import TelegramClient, events

from windsurf_controller import desktop_controller
from ai_processor import ai_processor


load_dotenv()

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
_LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
logging.basicConfig(level=getattr(logging, _LOG_LEVEL, logging.INFO))
logger = logging.getLogger("telethon_bot")


def _chunk_text(text: str, max_len: int = 4096) -> List[str]:
    chunks: List[str] = []
    remaining = text or ""
    while remaining:
        if len(remaining) <= max_len:
            chunks.append(remaining)
            break
        split_at = remaining.rfind("\n", 0, max_len)
        if split_at == -1:
            split_at = max_len
        chunks.append(remaining[:split_at])
        remaining = remaining[split_at:]
    return chunks


async def send_chunks(event: events.NewMessage.Event, text: str):
    if not text:
        return
    chunks = _chunk_text(text)
    logger.info(f"[send_chunks] sending {len(chunks)} chunk(s), total_len={len(text)}")
    for i, chunk in enumerate(chunks):
        logger.debug(f"[send_chunks] chunk {i+1}/{len(chunks)} len={len(chunk)}")
        await event.respond(chunk)


def _status_text() -> str:
    diag = desktop_controller.get_diagnostics()
    lines = [
        "üìä –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã:",
        f"–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞: {diag.get('platform')}",
        f"Windsurf –ø—Ä–æ—Ü–µ—Å—Å–æ–≤: {len(diag.get('windsurf_pids', []))} ‚Äî {diag.get('windsurf_pids')}",
        f"Windows automation: {'‚úÖ' if diag.get('windows_automation') else '‚ùå'}",
        f"–£—Å–ø–µ—à–Ω—ã—Ö –æ—Ç–ø—Ä–∞–≤–æ–∫: {diag.get('success_sends')}",
        f"–ù–µ—É—Å–ø–µ—à–Ω—ã—Ö –æ—Ç–ø—Ä–∞–≤–æ–∫: {diag.get('failed_sends')}",
        f"–ü–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {diag.get('last_error') or '‚Äî'}",
        f"last_paste_strategy: {diag.get('last_paste_strategy') or '‚Äî'}",
        f"last_copy_method: {diag.get('last_copy_method') or '‚Äî'}",
        f"last_copy_length: {diag.get('last_copy_length')}",
        f"last_copy_is_echo: {diag.get('last_copy_is_echo')}",
        f"response_wait_loops: {diag.get('response_wait_loops')}",
        f"response_ready_time: {diag.get('response_ready_time')}s",
        f"response_stabilized: {diag.get('response_stabilized')}",
        f"response_stabilized_by: {diag.get('response_stabilized_by')}",
        f"last_ui_button: {diag.get('last_ui_button')}",
        f"last_ui_avg_color: {diag.get('last_ui_avg_color')}",
        f"last_visual_region: {diag.get('last_visual_region')}",
        f"last_click_xy: {diag.get('last_click_xy')}",
        f"last_ready_pixel: {diag.get('last_ready_pixel')}",
        f"last_model_set: {diag.get('last_model_set')}",
        f"cpu_quiet_seconds: {diag.get('cpu_quiet_seconds')}",
        f"cpu_last_total_percent: {diag.get('cpu_last_total_percent')}",
        "",
        "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:",
        f"RESPONSE_WAIT_SECONDS={diag.get('RESPONSE_WAIT_SECONDS')}",
        f"RESPONSE_MAX_WAIT_SECONDS={diag.get('RESPONSE_MAX_WAIT_SECONDS')}",
        f"RESPONSE_POLL_INTERVAL_SECONDS={diag.get('RESPONSE_POLL_INTERVAL_SECONDS')}",
        f"RESPONSE_STABLE_MIN_SECONDS={diag.get('RESPONSE_STABLE_MIN_SECONDS')}",
        f"PASTE_RETRY_COUNT={diag.get('PASTE_RETRY_COUNT')}",
        f"COPY_RETRY_COUNT={diag.get('COPY_RETRY_COUNT')}",
        f"USE_UI_BUTTON_DETECTION={os.getenv('USE_UI_BUTTON_DETECTION')}",
        f"SEND_BTN_REGION_RIGHT={os.getenv('SEND_BTN_REGION_RIGHT')}",
        f"SEND_BTN_REGION_BOTTOM={os.getenv('SEND_BTN_REGION_BOTTOM')}",
        f"SEND_BTN_REGION_W={os.getenv('SEND_BTN_REGION_W')}",
        f"SEND_BTN_REGION_H={os.getenv('SEND_BTN_REGION_H')}",
        f"SEND_BTN_BLUE_DELTA={os.getenv('SEND_BTN_BLUE_DELTA')}",
        f"SEND_BTN_WHITE_BRIGHT={os.getenv('SEND_BTN_WHITE_BRIGHT')}",
        f"USE_VISUAL_STABILITY={os.getenv('USE_VISUAL_STABILITY')}",
        f"VISUAL_REGION_TOP={os.getenv('VISUAL_REGION_TOP')}",
        f"VISUAL_REGION_BOTTOM={os.getenv('VISUAL_REGION_BOTTOM')}",
        f"VISUAL_SAMPLE_INTERVAL_SECONDS={os.getenv('VISUAL_SAMPLE_INTERVAL_SECONDS')}",
        f"VISUAL_DIFF_THRESHOLD={os.getenv('VISUAL_DIFF_THRESHOLD')}",
        f"VISUAL_STABLE_SECONDS={os.getenv('VISUAL_STABLE_SECONDS')}",
        f"SAVE_VISUAL_DEBUG={os.getenv('SAVE_VISUAL_DEBUG')}",
        f"SAVE_VISUAL_DIR={os.getenv('SAVE_VISUAL_DIR')}",
        f"RIGHT_CLICK_X_FRACTION={os.getenv('RIGHT_CLICK_X_FRACTION')}",
        f"RIGHT_CLICK_Y_OFFSET={os.getenv('RIGHT_CLICK_Y_OFFSET')}",
        f"USE_COPY_SHORT_FALLBACK={os.getenv('USE_COPY_SHORT_FALLBACK')}",
        f"USE_READY_PIXEL={os.getenv('USE_READY_PIXEL')}",
        f"READY_PIXEL_REQUIRED={os.getenv('READY_PIXEL_REQUIRED')}",
        f"READY_PIXEL_SRC={os.getenv('READY_PIXEL_SRC')}",
        f"READY_PIXEL_AVG_K={os.getenv('READY_PIXEL_AVG_K')}",
        f"READY_PIXEL_REQUIRE_TRANSITION={os.getenv('READY_PIXEL_REQUIRE_TRANSITION')}",
        f"READY_PIXEL_STABLE_SECONDS={os.getenv('READY_PIXEL_STABLE_SECONDS')}",
        f"READY_PIXEL_TRANSITION_TIMEOUT_SECONDS={os.getenv('READY_PIXEL_TRANSITION_TIMEOUT_SECONDS')}",
        f"READY_PIXEL=(x={os.getenv('READY_PIXEL_X')}, y={os.getenv('READY_PIXEL_Y')}, rgb=({os.getenv('READY_PIXEL_R')},{os.getenv('READY_PIXEL_G')},{os.getenv('READY_PIXEL_B')}), tol={os.getenv('READY_PIXEL_TOL')}, tol_pct={os.getenv('READY_PIXEL_TOL_PCT')})",
        f"ANSWER_ABS=(x={os.getenv('ANSWER_ABS_X')}, y={os.getenv('ANSWER_ABS_Y')})",
        f"INPUT_ABS=(x={os.getenv('INPUT_ABS_X')}, y={os.getenv('INPUT_ABS_Y')})",
        "",
        "AI:",
        f"Gemini –º–æ–¥–µ–ª—å: {ai_processor.get_model_name() or '‚Äî'}",
    ]
    return "\n".join(lines)


async def handle_start(event: events.NewMessage.Event):
    logger.info("Handling /start")
    text = (
        "ü§ñ –ë–æ—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Windsurf Desktop\n\n"
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "/status ‚Äî —Å—Ç–∞—Ç—É—Å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n"
        "/model ‚Äî —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—å—é API (list/set/current)\n"
        "/wsmodel set [#N|@sub] <name> ‚Äî –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –º–æ–¥–µ–ª—å –≤ UI Windsurf (Cmd+/ ‚Üí –≤–≤–µ—Å—Ç–∏ ‚Üí Enter)\n"
        "/whoami ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å –≤–∞—à Telegram user_id\n"
        "/windows ‚Äî —Å–ø–∏—Å–æ–∫ –æ–∫–æ–Ω Windsurf (macOS)\n\n"
        "–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, —á—Ç–æ–±—ã –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –µ–≥–æ –≤ Windsurf!"
    )
    await send_chunks(event, text)


async def handle_status(event: events.NewMessage.Event):
    logger.info("Handling /status")
    await send_chunks(event, _status_text())


async def handle_windows(event: events.NewMessage.Event):
    logger.info("Handling /windows")
    titles = desktop_controller.list_windows()
    if not titles:
        await event.respond("–û–∫–æ–Ω Windsurf –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–ª–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ.")
        return
    lines = ["ü™ü –û–∫–Ω–∞ Windsurf:"]
    for i, t in enumerate(titles, start=1):
        lines.append(f"#{i}: {t}")
    lines.append("\n–û—Ç–ø—Ä–∞–≤–ª—è–π—Ç–µ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º: [#N] –≤–∞—à —Ç–µ–∫—Å—Ç –∏–ª–∏ [@—á–∞—Å—Ç—å_–∑–∞–≥–æ–ª–æ–≤–∫–∞] –≤–∞—à —Ç–µ–∫—Å—Ç")
    await send_chunks(event, "\n".join(lines))


async def handle_model(event: events.NewMessage.Event):
    logger.info("Handling /model")
    text = (event.raw_text or "").strip()
    parts = text.split()
    if len(parts) == 1:
        help_text = (
            "‚öôÔ∏è –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—å—é API (—á–µ—Ä–µ–∑ ai_processor):\n"
            "‚Ä¢ /model current ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å\n"
            "‚Ä¢ /model list ‚Äî —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π\n"
            "‚Ä¢ /model list pro ‚Äî —Å–ø–∏—Å–æ–∫, —Ñ–∏–ª—å—Ç—Ä –ø–æ –ø–æ–¥—Å—Ç—Ä–æ–∫–µ\n"
            "‚Ä¢ /model set <name> ‚Äî —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å\n"
            "\n–î–ª—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –≤ UI Windsurf –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ: /wsmodel set [#N|@sub] <name>"
        )
        await send_chunks(event, help_text)
        return

    sub = parts[1].lower()
    if sub == "current":
        logger.debug("/model current")
        await event.respond(f"–¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {ai_processor.get_model_name() or '‚Äî'}")
        return

    if sub == "list":
        logger.debug("/model list")
        models = ai_processor.list_models()
        if len(parts) >= 3:
            filt = " ".join(parts[2:]).lower()
            models = [m for m in models if filt in m.lower()]
        if not models:
            await event.respond("–°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –ø—É—Å—Ç")
            return
        lines = ["üìö –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:"] + [f"‚Ä¢ {m}" for m in models[:100]]
        await send_chunks(event, "\n".join(lines))
        return

    if sub == "set" and len(parts) >= 3:
        new_model = " ".join(parts[2:]).strip()
        logger.debug(f"/model set -> {new_model}")
        ok, msg = ai_processor.set_model(new_model)
        prefix = "‚úÖ" if ok else "‚ùå"
        await event.respond(f"{prefix} {msg}")
        return

    await event.respond("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –ø–æ–¥–∫–æ–º–∞–Ω–¥–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /model –¥–ª—è –ø–æ–º–æ—â–∏.")


def _parse_target_prefix(s: str) -> tuple[Optional[str], str]:
    """–ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–µ—Ñ–∏–∫—Å–∞ [#N] –∏–ª–∏ [@substr] –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (target, rest)."""
    import re
    s = s.strip()
    m = re.match(r"^\[(#\d+|@[^\]]+)\]\s*(.*)$", s)
    if not m:
        return None, s
    token = m.group(1)
    rest = m.group(2).strip()
    if token.startswith('#') and token[1:].isdigit():
        return f"index:{int(token[1:])}", rest
    if token.startswith('@'):
        return token[1:], rest
    return None, s


async def handle_wsmodel(event: events.NewMessage.Event):
    logger.info("Handling /wsmodel")
    text = (event.raw_text or "").strip()
    parts = text.split(maxsplit=2)
    if len(parts) < 2:
        await event.respond(
            "‚öôÔ∏è –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ UI Windsurf:\n"
            "‚Ä¢ /wsmodel set <name> ‚Äî –∞–∫—Ç–∏–≤–Ω–æ–µ –æ–∫–Ω–æ\n"
            "‚Ä¢ /wsmodel set [#N] <name> ‚Äî –æ–∫–Ω–æ –ø–æ –∏–Ω–¥–µ–∫—Å—É –≤ /windows\n"
            "‚Ä¢ /wsmodel set [@—á–∞—Å—Ç—å_–∑–∞–≥–æ–ª–æ–≤–∫–∞] <name> ‚Äî –æ–∫–Ω–æ –ø–æ —á–∞—Å—Ç–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞\n"
            "–ü—Ä–∏–Ω—Ü–∏–ø: Cmd+/ ‚Üí –≤–≤–µ—Å—Ç–∏ <name> ‚Üí Enter"
        )
        return
    sub = parts[1].lower()
    if sub != 'set':
        await event.respond("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –ø–æ–¥–∫–æ–º–∞–Ω–¥–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /wsmodel set ...")
        return
    if len(parts) < 3:
        await event.respond("–£–∫–∞–∂–∏—Ç–µ –∏–º—è –º–æ–¥–µ–ª–∏: /wsmodel set <name>")
        return
    payload = parts[2]
    target, name = _parse_target_prefix(payload)
    if not name:
        await event.respond("–ü—É—Å—Ç–æ–µ –∏–º—è –º–æ–¥–µ–ª–∏")
        return
    ok, msg = desktop_controller.set_model_ui(name, target or "active")
    prefix = "‚úÖ" if ok else "‚ùå"
    await event.respond(f"{prefix} {msg}")


async def handle_whoami(event: events.NewMessage.Event):
    logger.info("Handling /whoami")
    try:
        sender = await event.get_sender()
        uid = getattr(sender, 'id', None)
        uname = getattr(sender, 'username', None)
    except Exception:
        sender = None
        uid = event.sender_id
        uname = None
    await event.respond(f"–í–∞—à user_id: {uid}\nusername: @{uname}")


async def main_async():
    api_id = int(os.getenv("TELEGRAM_API_ID", "0"))
    api_hash = os.getenv("TELEGRAM_API_HASH")
    bot_token = os.getenv("TELEGRAM_BOT_TOKEN")
    session_name = (os.getenv("TELETHON_SESSION_NAME") or "windsurf_telethon_bot").strip() or "windsurf_telethon_bot"
    if not api_id or not api_hash or not bot_token:
        logger.error("TELEGRAM_API_ID, TELEGRAM_API_HASH –∏–ª–∏ TELEGRAM_BOT_TOKEN –Ω–µ –∑–∞–¥–∞–Ω—ã –≤ .env")
        return

    client = TelegramClient(session_name, api_id, api_hash)
    await client.connect()
    try:
        authorized = await client.is_user_authorized()
    except Exception:
        authorized = False
    if not authorized:
        logger.info("Bot session not authorized, signing in with bot token...")
        await client.sign_in(bot_token=bot_token)
    else:
        logger.info("Reusing existing authorized bot session")

    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤
    client.add_event_handler(handle_start, events.NewMessage(pattern=r"^/start(?:@\w+)?$"))
    client.add_event_handler(handle_status, events.NewMessage(pattern=r"^/status(?:@\w+)?$"))
    client.add_event_handler(handle_windows, events.NewMessage(pattern=r"^/windows(?:@\w+)?$"))
    client.add_event_handler(handle_model, events.NewMessage(pattern=r"^/model(?:\b.*)?$"))
    client.add_event_handler(handle_wsmodel, events.NewMessage(pattern=r"^/wsmodel(?:\b.*)?$"))
    client.add_event_handler(handle_whoami, events.NewMessage(pattern=r"^/whoami(?:@\w+)?$"))

    logger.info("Telethon –±–æ—Ç –∑–∞–ø—É—â–µ–Ω. –û–∂–∏–¥–∞—é –∫–æ–º–∞–Ω–¥—ã‚Ä¶")

    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –∞–≤—Ç–æ-—Å—Ç–æ–ø —á–µ—Ä–µ–∑ BOT_RUN_SECONDS (–¥–ª—è healthcheck 10 —Å–µ–∫)
    run_for = 0
    try:
        run_for = int(float(os.getenv("BOT_RUN_SECONDS", "0")))
    except Exception:
        run_for = 0

    if run_for > 0:
        async def _stopper():
            await asyncio.sleep(run_for)
            logger.info(f"–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é Telethon –±–æ—Ç–∞ –ø–æ —Ç–∞–π–º–µ—Ä—É {run_for}s‚Ä¶")
            await client.disconnect()
        asyncio.create_task(_stopper())

    await client.run_until_disconnected()


if __name__ == "__main__":
    try:
        asyncio.run(main_async())
    except KeyboardInterrupt:
        pass
